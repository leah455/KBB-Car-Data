from requests import get
from bs4 import BeautifulSoup
import pandas as pd
from time import sleep
import time
from random import randint
from IPython.core.display import clear_output
import warnings

#Create lists to store scraped data
names = []
starting_prices = []
combined_mpgs = []
expert_ratings = []
consumer_ratings = []

#To iterate through 973 pages
pages = [str(i) for i in range(1,974)]

#Define start time of the requests and the number of requests
start_time = time.time()
requests = 0


for page in pages:

    #Website to scrape
    response = get('https://www.kbb.com/car-finder/' + page)

    #Pause the loop randomly between 5 and 15 seconds
    sleep(randint(5, 15))

    #Track the number of requests made as well as the frequency of the requests
    requests += 1
    elapsed_time = time.time() - start_time
    print('Request:{}; Frequency: {} requests/s'.format(requests, requests/elapsed_time))
    clear_output(wait = True)

    #Warning if there is a non-200 status code
    if response.status_code != 200:
        warnings.warn('Request: {}; Status code: {}'.format(requests, response.status_code))
    
    #Warn and break loop if the number of requests is greater than 974
    if requests > 974:
        warnings.warn('Number of requests was greater than expected.')
        break
    
    #Parse content of request with BeautifulSoup
    soup = BeautifulSoup(response.content, 'html.parser')

    #Select containers for the 10 cars per page
    car_containers = soup.find_all('a', class_ = 'css-y4ixr8 e5qxycd0')

    #For every car on a single page
    for container in car_containers:
        #If car has all the values then,
        if (container.find('div', attrs = {'title': 'Combined Fuel Economy'}) is not None) and (container.find('div', attrs = {'title': 'KBB.com Expert Rating'}) is not None) and (container.find('div', attrs = {'title': 'KBB.com Consumer Rating'}) is not None):

            #Name of the car
            name = container.h2.text
            names.append(name)

            #Starting price 
            starting_price = container.h3.text
            starting_prices.append(starting_price)

            #Total combined mpg (highway + city)
            combined_mpg = container.find('div', attrs = {'title': 'Combined Fuel Economy'}).h3.text
            combined_mpgs.append(combined_mpg)

            #Kelly Blue Book expert rating
            expert_rating = container.find('div', attrs = {'title': 'KBB.com Expert Rating'}).span.text
            expert_ratings.append(expert_rating)

            #Kelly Blue Book consumer rating
            consumer_rating = container.find('div', attrs = {'title': 'KBB.com Consumer Rating'}).span.text
            consumer_ratings.append(consumer_rating)

#Convert scraped data into a pandas dataframe
data = pd.DataFrame({'car': names,
    'starting_price': starting_prices,
    'combined_mpg': combined_mpgs,
    'expert_rating': expert_ratings,
    'consumer_rating': consumer_ratings})

#Store dataframe as csv file
data.to_csv('kbb_scrape_data.csv')

#Check to see if the data was scraped correctly
print(data.info())
print(data.head())